# Canvas LMS Daily Digest

**Version 1.0.0** | [Changelog](CHANGELOG.md)

A daily RSS feed aggregator for Canvas LMS release notes, community discussions, and status updates. Designed for educational technologists who want to stay informed about Canvas updates without manually checking multiple sources.

## Features

- **Multi-source aggregation** - Collects updates from Instructure Community (release notes, changelog, Q&A, blog), Reddit discussions, and Canvas status page
- **AI-powered summaries** - Uses Google Gemini to generate concise summaries, sentiment analysis, and topic classification
- **Feature-centric organization** - RSS items grouped by Canvas feature (Gradebook, Assignments, Quizzes, etc.) rather than by source
- **Privacy-focused** - Automatically redacts personal information and anonymizes Reddit usernames
- **Docker deployment** - Ready-to-deploy containerized setup with cron scheduling
- **Deduplication** - SQLite-backed history prevents duplicate items across runs

## Quick Start

### Prerequisites

- Python 3.11+
- Docker and Docker Compose (for containerized deployment)
- API credentials:
  - [Google Gemini API key](https://ai.google.dev/)
  - [Reddit API credentials](https://www.reddit.com/prefs/apps) (optional)

### Local Development

```bash
# Clone the repository
git clone https://github.com/yourusername/canvas-rss.git
cd canvas-rss

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Run the aggregator
python src/main.py
```

### Docker Deployment

```bash
# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Build and start containers
docker-compose up -d

# View logs
docker-compose logs -f

# Run manually (don't wait for cron)
docker-compose exec canvas-rss-aggregator python src/main.py
```

The RSS feed will be available at `http://localhost:8080/feed.xml`.

## Configuration

### Environment Variables

Create a `.env` file with the following:

```bash
# Required: Google Gemini API
GEMINI_API_KEY=your_gemini_api_key

# Optional: Reddit API (enables Reddit monitoring)
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=canvas-rss-aggregator:v1.0.0

# Optional: Customization
GEMINI_MODEL=gemini-2.0-flash       # AI model to use
CRON_SCHEDULE=0 6 * * *              # Daily at 6 AM (default)
TZ=America/Toronto                   # Timezone
FEED_PORT=8080                       # Feed server port
FEED_HOST=0.0.0.0                    # Feed server host
```

### config.yaml

The `config/config.yaml` file controls data sources and processing options:

```yaml
sources:
  instructure_community:
    enabled: true
    max_pages: 3
  reddit:
    enabled: true
    min_score: 5
  status_page:
    enabled: true

processing:
  summarization:
    max_length: 300
  sentiment_analysis:
    enabled: true
  topic_classification:
    enabled: true

rss:
  title: Canvas LMS Daily Digest
  max_items: 50
```

## RSS Feed Format

Items are organized by Canvas feature with source badges:

```
Gradebook - [ğŸ“¢ Community] New weighted grading option
Assignments - [ğŸ’¬ Reddit] Discussion about late submissions
Performance - [ğŸ”§ Status] Maintenance complete
```

Each item includes:
- AI-generated summary
- Sentiment (positive/neutral/negative)
- Related topics
- Link to original source

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Daily Cron Job â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Collection Layer           â”‚
â”‚ â€¢ Instructure Community (Playwright)    â”‚
â”‚ â€¢ Reddit API (PRAW)                     â”‚
â”‚ â€¢ Canvas Status Page                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Processing & Analysis Layer        â”‚
â”‚ â€¢ Content Extraction                    â”‚
â”‚ â€¢ Duplicate Detection (SQLite)          â”‚
â”‚ â€¢ LLM Summarization (Gemini)            â”‚
â”‚ â€¢ Sentiment Analysis                    â”‚
â”‚ â€¢ Topic Classification                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Output Generation Layer         â”‚
â”‚ â€¢ RSS Feed Generation (feedgen)         â”‚
â”‚ â€¢ Historical Archive                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
canvas-rss/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # Application entry point
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ instructure_community.py  # Playwright web scraper
â”‚   â”‚   â”œâ”€â”€ reddit_client.py          # PRAW Reddit client
â”‚   â”‚   â””â”€â”€ status_page.py            # Status page monitor
â”‚   â”œâ”€â”€ processor/
â”‚   â”‚   â””â”€â”€ content_processor.py      # Gemini AI processing
â”‚   â”œâ”€â”€ generator/
â”‚   â”‚   â””â”€â”€ rss_builder.py            # RSS feed generation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ database.py               # SQLite operations
â”‚       â””â”€â”€ logger.py                 # Logging configuration
â”œâ”€â”€ tests/                         # Test suite (270 tests)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                # Configuration file
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ requirements.txt
```

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test file
pytest tests/test_rss_builder.py -v
```

## Data Sources

| Source | Method | Content |
|--------|--------|---------|
| [Instructure Community](https://community.instructure.com/) | Playwright | Release notes, changelog, Q&A, blog |
| [Reddit](https://reddit.com/r/canvas) | PRAW API | r/canvas, r/instructionaldesign discussions |
| [Canvas Status](https://status.instructure.com/) | API | Incidents, maintenance updates |

## Deployment Options

The Docker container serves the RSS feed on `localhost:8080`. For production, use a reverse proxy:

- **Cloudflare Tunnel** - Zero port forwarding, automatic SSL
- **Nginx/Caddy** - Traditional reverse proxy with Let's Encrypt
- **Cloud platforms** - AWS ECS, Google Cloud Run, DigitalOcean

See [specs/canvas-rss.md](specs/canvas-rss.md) for detailed deployment guides.

## Troubleshooting

**Empty RSS feed**
- Check logs: `docker-compose logs canvas-rss-aggregator`
- Verify API keys in `.env`
- Run manually: `docker-compose exec canvas-rss-aggregator python src/main.py`

**Playwright fails**
- Ensure Chromium is installed: `playwright install chromium`
- In Docker, the image includes Chromium automatically

**Reddit API errors**
- Verify credentials at https://www.reddit.com/prefs/apps
- Check rate limits in logs

**Gemini API timeouts**
- The aggregator includes exponential backoff retry logic
- Check your API quota at https://ai.google.dev/

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Make your changes
4. Run tests: `pytest tests/ -v`
5. Commit: `git commit -m "Add my feature"`
6. Push: `git push origin feature/my-feature`
7. Open a pull request

## License

MIT License - see [LICENSE](LICENSE) for details.

## Acknowledgments

- Built for educational technologists at the University of Toronto
- Uses [Playwright](https://playwright.dev/) for web scraping
- Uses [PRAW](https://praw.readthedocs.io/) for Reddit API
- Uses [feedgen](https://feedgen.kiesow.be/) for RSS generation
- AI summaries powered by [Google Gemini](https://ai.google.dev/)
