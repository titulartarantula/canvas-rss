# v1.3.1 Integration Fix Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Fix the disconnect between v1.3.0 formatting functions and the RSS output pipeline so structured content actually appears in the feed.

**Root Cause:** The v1.3.0 implementation created formatting functions (`build_release_note_entry`, `build_deploy_note_entry`, `format_discussion_description`) but:
1. RSS builder's `_format_description()` was never updated to use them
2. `enrich_with_llm()` overwrites structured content
3. Deploy notes parsing returns empty data (stub implementation)
4. Release notes parsing is incomplete (missing table_data, upcoming_changes)

**Architecture Decision:** Use a new `structured_description` field on ContentItem to preserve structured content through the pipeline, and update RSS builder to use it when present.

---

## Overview

| Phase | Tasks | Description |
|-------|-------|-------------|
| 1 | 1-3 | ContentItem and pipeline fix |
| 2 | 4-6 | RSS builder update |
| 3 | 7-10 | Complete deploy notes parsing |
| 4 | 11-14 | Complete release notes parsing |
| 5 | 15-17 | LLM per-feature summaries |
| 6 | 18 | Integration test |

---

# Phase 1: ContentItem and Pipeline Fix

## Task 1: Add structured_description field to ContentItem

**Files:**
- Modify: `src/processor/content_processor.py:58-80`
- Test: `tests/test_processor.py`

**Step 1: Write failing test**

```python
def test_content_item_structured_description():
    """Test ContentItem has structured_description field."""
    item = ContentItem(
        source="community",
        source_id="test_123",
        title="Test",
        url="https://example.com",
        content="raw content",
        structured_description="━━━ NEW FEATURES ━━━\n▸ Test Feature"
    )
    assert item.structured_description == "━━━ NEW FEATURES ━━━\n▸ Test Feature"

def test_content_item_structured_description_default():
    """Test structured_description defaults to empty string."""
    item = ContentItem(
        source="community",
        source_id="test_123",
        title="Test",
        url="https://example.com",
        content="raw content"
    )
    assert item.structured_description == ""
```

**Step 2: Add field to ContentItem dataclass**

```python
@dataclass
class ContentItem:
    # ... existing fields ...
    structured_description: str = ""  # v1.3.0+ formatted description (preserved through pipeline)
```

**Done when:** Tests pass, ContentItem accepts structured_description field.

---

## Task 2: Update main.py to use structured_description

**Files:**
- Modify: `src/main.py:136-313`
- Test: `tests/test_main.py`

**Step 1: Write failing test**

```python
def test_process_discussion_posts_sets_structured_description():
    """Test that discussion items have structured_description set."""
    # ... setup mock posts and db ...
    items = process_discussion_posts(posts, db, scraper)
    assert items[0].structured_description != ""
    assert "━━━" in items[0].structured_description
```

**Step 2: Update process_discussion_posts()**

Change line ~181 from:
```python
item = ContentItem(
    ...
    content=description,
    ...
)
```

To:
```python
item = ContentItem(
    ...
    content=post.content,  # Keep original for LLM
    structured_description=description,  # Store formatted version
    ...
)
```

**Step 3: Update process_release_notes()**

Change lines ~237-248 similarly - store `description` in `structured_description`, keep original content in `content`.

**Step 4: Update process_deploy_notes()**

Same pattern for deploy notes.

**Done when:** All three process_* functions populate structured_description.

---

## Task 3: Update enrich_with_llm to preserve structured_description

**Files:**
- Modify: `src/processor/content_processor.py:569-609`
- Test: `tests/test_processor.py`

**Step 1: Write failing test**

```python
def test_enrich_preserves_structured_description():
    """Test that enrich_with_llm does not overwrite structured_description."""
    processor = ContentProcessor()
    item = ContentItem(
        source="community",
        source_id="test",
        title="Test",
        url="https://example.com",
        content="raw content",
        structured_description="━━━ PRESERVED ━━━"
    )
    enriched = processor.enrich_with_llm([item])
    assert enriched[0].structured_description == "━━━ PRESERVED ━━━"
```

**Step 2: Verify no modification**

The current code only modifies `content`, `title`, `summary`, `sentiment`, `topics`, and `primary_topic`. Verify `structured_description` is not touched.

**Done when:** Test passes confirming structured_description survives enrichment.

---

# Phase 2: RSS Builder Update

## Task 4: Update _format_description to use structured_description

**Files:**
- Modify: `src/generator/rss_builder.py:379-409`
- Test: `tests/test_rss_builder.py`

**Step 1: Write failing test**

```python
def test_format_description_uses_structured_when_present():
    """Test that structured_description is used when available."""
    builder = RSSBuilder()
    item = ContentItem(
        source="community",
        source_id="test",
        title="Test",
        url="https://example.com",
        content="raw content",
        structured_description="━━━ NEW FEATURES ━━━\n▸ Test Feature\nAvailability: Admin-enabled"
    )
    description = builder._format_description(item)
    assert "━━━ NEW FEATURES ━━━" in description
    assert "<h3>Summary</h3>" not in description

def test_format_description_fallback_to_legacy():
    """Test fallback to HTML format when no structured_description."""
    builder = RSSBuilder()
    item = ContentItem(
        source="community",
        source_id="test",
        title="Test",
        url="https://example.com",
        content="raw content",
        summary="A summary"
    )
    description = builder._format_description(item)
    assert "<h3>Summary</h3>" in description
```

**Step 2: Update _format_description method**

```python
def _format_description(self, item: ContentItem) -> str:
    """Format item description.

    Uses structured_description if available (v1.3.0+ items),
    otherwise falls back to legacy HTML format.
    """
    # v1.3.0+ items have pre-formatted structured descriptions
    if item.structured_description:
        return item.structured_description

    # Legacy format for non-v1.3.0 items (Reddit, Status, etc.)
    parts = []
    summary = item.summary if item.summary else item.content[:500] if item.content else ""
    if summary:
        parts.append(f"<h3>Summary</h3>\n<p>{summary}</p>")
    # ... rest of legacy format ...
```

**Done when:** Tests pass, structured content appears in RSS output.

---

## Task 5: Update add_item to handle structured content

**Files:**
- Modify: `src/generator/rss_builder.py:411-477`
- Test: `tests/test_rss_builder.py`

**Step 1: Write test for CDATA handling**

```python
def test_add_item_structured_content_in_cdata():
    """Test that structured content is wrapped properly for RSS."""
    builder = RSSBuilder()
    item = ContentItem(
        source="community",
        source_id="release_123",
        title="[NEW] Canvas Release Notes",
        url="https://example.com",
        content="raw",
        content_type="release_note",
        structured_description="━━━ NEW FEATURES ━━━\n▸ Feature"
    )
    item.has_v130_badge = True
    builder.add_item(item)

    feed = builder.create_feed()
    assert "━━━ NEW FEATURES ━━━" in feed
```

**Step 2: Verify CDATA wrapping**

feedgen should handle special characters. Verify the structured content with unicode (━, ▸, ⚠️, ⏸️) renders correctly.

**Done when:** Unicode section dividers appear correctly in RSS XML.

---

## Task 6: Fix title formatting for v1.3.0 items

**Files:**
- Modify: `src/generator/rss_builder.py:335-378`
- Test: `tests/test_rss_builder.py`

**Current problem:** Titles show as `Gradebook - [NEW] Canvas Release Notes` but should be `[NEW] Canvas Release Notes (2026-02-01)` per design.

**Step 1: Write failing test**

```python
def test_format_title_v130_no_topic_prefix():
    """v1.3.0 items should not get topic prefix - badge is enough."""
    builder = RSSBuilder()
    item = ContentItem(
        source="community",
        source_id="release_123",
        title="[NEW] Canvas Release Notes (2026-02-01)",
        url="https://example.com",
        content="raw",
        content_type="release_note",
        primary_topic="Gradebook"
    )
    item.has_v130_badge = True

    title = builder._format_title_with_badge(item)
    assert title == "[NEW] Canvas Release Notes (2026-02-01)"
    assert "Gradebook -" not in title
```

**Step 2: Update _format_title_with_badge**

```python
def _format_title_with_badge(self, item: ContentItem) -> str:
    # v1.3.0 items already have complete titles with badges
    if getattr(item, 'has_v130_badge', False):
        return item.title  # Use as-is, no modification

    # ... legacy formatting for non-v1.3.0 items ...
```

**Done when:** v1.3.0 titles appear exactly as constructed in main.py.

---

# Phase 3: Complete Deploy Notes Parsing

## Task 7: Implement deploy notes change parsing

**Files:**
- Modify: `src/scrapers/instructure_community.py:1264-1302`
- Test: `tests/test_scrapers.py`

**Step 1: Write failing test**

```python
def test_parse_deploy_note_page_extracts_changes(mock_page):
    """Test that changes are extracted from deploy notes page."""
    mock_page.query_selector_all.return_value = [
        MockElement(tag="h2", data_id="updated-features", text="Updated Features"),
        MockElement(tag="h3", data_id="gradebook", text="Gradebook"),
        MockElement(tag="h4", data_id="status-icons", text="Status Icons Added"),
    ]

    scraper = InstructureScraper()
    scraper.page = mock_page
    page = scraper.parse_deploy_note_page("https://example.com/deploy-notes")

    assert len(page.changes) == 1
    assert page.changes[0].name == "Status Icons Added"
    assert page.changes[0].category == "Gradebook"
    assert page.changes[0].section == "Updated Features"
```

**Step 2: Implement full parsing**

Mirror the release notes parsing logic but for deploy notes structure:

```python
def parse_deploy_note_page(self, url: str) -> Optional[DeployNotePage]:
    # ... existing setup code ...

    changes = []
    sections: Dict[str, List[DeployChange]] = {}
    current_section = "Updated Features"
    current_category = "General"

    headings = self.page.query_selector_all("h2[data-id], h3[data-id], h4[data-id]")

    for heading in headings:
        tag = heading.evaluate("el => el.tagName.toLowerCase()")
        data_id = heading.get_attribute("data-id") or ""
        text = heading.inner_text().strip()

        if tag == "h2":
            current_section = text
            if current_section not in sections:
                sections[current_section] = []
        elif tag == "h3":
            current_category = text
        elif tag == "h4":
            # Parse [Delayed as of DATE] annotation
            status = None
            status_date = None
            delayed_match = re.search(r'\[Delayed as of (\d{4}-\d{2}-\d{2})\]', text)
            if delayed_match:
                status = "delayed"
                status_date = datetime.strptime(delayed_match.group(1), "%Y-%m-%d")
                text = re.sub(r'\s*\[Delayed as of \d{4}-\d{2}-\d{2}\]', '', text)

            # Get content after heading
            raw_content = self._get_next_sibling_content(heading)

            change = DeployChange(
                category=current_category,
                name=text,
                anchor_id=data_id,
                section=current_section,
                raw_content=raw_content,
                table_data=None,
                status=status,
                status_date=status_date
            )
            changes.append(change)

            if current_section not in sections:
                sections[current_section] = []
            sections[current_section].append(change)

    return DeployNotePage(
        title=title,
        url=url,
        deploy_date=deploy_date,
        beta_date=beta_date,
        changes=changes,
        sections=sections
    )
```

**Done when:** parse_deploy_note_page returns populated DeployNotePage with changes.

---

## Task 8: Parse beta/production dates for deploy notes

**Files:**
- Modify: `src/scrapers/instructure_community.py:1264-1302`
- Test: `tests/test_scrapers.py`

**Step 1: Write failing test**

```python
def test_parse_deploy_note_page_extracts_dates(mock_page):
    """Test that beta and production dates are extracted."""
    mock_page.query_selector.return_value = MockElement(
        text="Beta: 2026-01-29 | Production: 2026-02-11"
    )

    scraper = InstructureScraper()
    scraper.page = mock_page
    page = scraper.parse_deploy_note_page("https://example.com/deploy-notes")

    assert page.beta_date == datetime(2026, 1, 29)
    assert page.deploy_date == datetime(2026, 2, 11)
```

**Step 2: Add date extraction**

Look for date metadata in page content (usually in an info box or header area):

```python
# Try to find beta/production dates in page
date_info = self.page.query_selector("[class*='date-info'], [class*='deploy-dates']")
if date_info:
    date_text = date_info.inner_text()
    beta_match = re.search(r'Beta:\s*(\d{4}-\d{2}-\d{2})', date_text)
    prod_match = re.search(r'Production:\s*(\d{4}-\d{2}-\d{2})', date_text)
    if beta_match:
        beta_date = datetime.strptime(beta_match.group(1), "%Y-%m-%d")
    if prod_match:
        deploy_date = datetime.strptime(prod_match.group(1), "%Y-%m-%d")
```

**Done when:** Beta and production dates are extracted when present.

---

## Task 9: Add helper method for sibling content extraction

**Files:**
- Modify: `src/scrapers/instructure_community.py`
- Test: `tests/test_scrapers.py`

**Step 1: Write test**

```python
def test_get_next_sibling_content(mock_page):
    """Test helper extracts content after heading."""
    heading = MockElement()
    heading.evaluate.return_value = "<p>Feature description</p><table>...</table>"

    scraper = InstructureScraper()
    content = scraper._get_next_sibling_content(heading)

    assert "<p>Feature description</p>" in content
```

**Step 2: Add helper method**

```python
def _get_next_sibling_content(self, heading) -> str:
    """Extract content between this heading and the next heading."""
    try:
        # Get all siblings until next heading
        content = heading.evaluate("""
            el => {
                let content = [];
                let sibling = el.nextElementSibling;
                while (sibling && !sibling.matches('h1, h2, h3, h4, h5, h6')) {
                    content.push(sibling.outerHTML);
                    sibling = sibling.nextElementSibling;
                }
                return content.join('');
            }
        """)
        return content or ""
    except Exception:
        return ""
```

**Done when:** Helper method extracts full content between headings.

---

## Task 10: Extract table_data for deploy changes

**Files:**
- Modify: `src/scrapers/instructure_community.py`
- Test: `tests/test_scrapers.py`

**Step 1: Write failing test**

```python
def test_parse_feature_table_data(mock_page):
    """Test configuration table parsing."""
    table_html = """
    <table>
        <tr><td>Enabled</td><td>Account Settings</td></tr>
        <tr><td>Default</td><td>Off</td></tr>
        <tr><td>Permissions</td><td>Admin only</td></tr>
    </table>
    """
    scraper = InstructureScraper()
    table_data = scraper._parse_feature_table(table_html)

    assert table_data.enable_location == "Account Settings"
    assert table_data.default_status == "Off"
    assert table_data.permissions == "Admin only"
```

**Step 2: Add table parsing method**

```python
def _parse_feature_table(self, raw_content: str) -> Optional[FeatureTableData]:
    """Parse configuration table from feature content."""
    if not raw_content or '<table' not in raw_content.lower():
        return None

    try:
        # Use BeautifulSoup or regex to extract table data
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(raw_content, 'html.parser')
        table = soup.find('table')
        if not table:
            return None

        data = {}
        for row in table.find_all('tr'):
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 2:
                key = cells[0].get_text().strip().lower()
                value = cells[1].get_text().strip()
                data[key] = value

        return FeatureTableData(
            enable_location=data.get('enabled', data.get('enable', '')),
            default_status=data.get('default', ''),
            permissions=data.get('permissions', ''),
            affected_areas=self._extract_areas(data.get('affects', '')),
            affects_roles=self._extract_roles(data.get('affects', ''))
        )
    except Exception as e:
        logger.debug(f"Error parsing feature table: {e}")
        return None
```

**Done when:** Feature tables are parsed into FeatureTableData objects.

---

# Phase 4: Complete Release Notes Parsing

## Task 11: Parse upcoming_changes section

**Files:**
- Modify: `src/scrapers/instructure_community.py:1169-1262`
- Test: `tests/test_scrapers.py`

**Step 1: Write failing test**

```python
def test_parse_release_note_upcoming_changes(mock_page):
    """Test upcoming changes section is parsed."""
    # Mock page with Upcoming Canvas Changes section
    page = scraper.parse_release_note_page("https://example.com/release")

    assert len(page.upcoming_changes) > 0
    assert page.upcoming_changes[0].date is not None
    assert page.upcoming_changes[0].description != ""
    assert page.upcoming_changes[0].days_until >= 0
```

**Step 2: Add upcoming changes parsing**

Look for the "Upcoming Canvas Changes" section and parse the list:

```python
# Parse Upcoming Canvas Changes section
upcoming_section = self.page.query_selector("[data-id='upcoming-canvas-changes']")
if upcoming_section:
    list_items = upcoming_section.query_selector_all("li")
    for li in list_items:
        text = li.inner_text().strip()
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', text)
        if date_match:
            change_date = datetime.strptime(date_match.group(1), "%Y-%m-%d")
            days_until = (change_date - datetime.now()).days
            description = re.sub(r'\d{4}-\d{2}-\d{2}:\s*', '', text)

            upcoming_changes.append(UpcomingChange(
                date=change_date,
                description=description,
                days_until=max(0, days_until)
            ))
```

**Done when:** Upcoming changes are parsed with dates and days_until calculated.

---

## Task 12: Parse table_data for release features

**Files:**
- Modify: `src/scrapers/instructure_community.py:1169-1262`
- Test: `tests/test_scrapers.py`

Reuse the `_parse_feature_table()` helper from Task 10.

**Step 1: Update feature parsing to include table**

```python
# Inside the h4 handling block:
raw_content = self._get_next_sibling_content(heading)
table_data = self._parse_feature_table(raw_content)

feature = Feature(
    category=current_category,
    name=text,
    anchor_id=data_id,
    added_date=added_date,
    raw_content=raw_content,
    table_data=table_data  # Now populated
)
```

**Done when:** Features have table_data populated when tables exist.

---

## Task 13: Add format_availability helper

**Files:**
- Modify: `src/processor/content_processor.py`
- Test: `tests/test_processor.py`

**Step 1: Verify existing implementation**

Check if `format_availability()` is already implemented. If not:

```python
def format_availability(table_data: Optional[FeatureTableData]) -> str:
    """Format availability info from table data.

    Args:
        table_data: Parsed configuration table, or None.

    Returns:
        Formatted string like "Admin-enabled at account level; affects instructors in Assignments"
    """
    if not table_data:
        return "Automatic update"

    parts = []

    # Permissions and location
    if table_data.permissions and table_data.enable_location:
        parts.append(f"{table_data.permissions}-enabled at {table_data.enable_location}")
    elif table_data.enable_location:
        parts.append(f"Enabled at {table_data.enable_location}")

    # Affected roles and areas
    if table_data.affects_roles or table_data.affected_areas:
        affects = []
        if table_data.affects_roles:
            affects.append(", ".join(table_data.affects_roles))
        if table_data.affected_areas:
            affects.append(f"in {', '.join(table_data.affected_areas)}")
        parts.append("affects " + " ".join(affects))

    return "; ".join(parts) if parts else "Automatic update"
```

**Done when:** Availability strings are formatted correctly.

---

## Task 14: Update build_release_note_entry to use LLM summaries

**Files:**
- Modify: `src/generator/rss_builder.py:98-141`
- Test: `tests/test_rss_builder.py`

**Current problem:** Line 137 has `parts.append("[Summary placeholder]")` - summaries aren't being generated.

**Solution:** LLM summaries need to be generated per-feature in the main.py flow and stored on the Feature objects. This is covered in Phase 5.

For now, update to use `raw_content` truncated as fallback:

```python
# Generate summary (placeholder until LLM integration)
if hasattr(feature, 'summary') and feature.summary:
    parts.append(feature.summary)
else:
    # Fallback: truncate raw content
    from bs4 import BeautifulSoup
    text = BeautifulSoup(feature.raw_content, 'html.parser').get_text()
    truncated = text[:200].rsplit(' ', 1)[0] + "..." if len(text) > 200 else text
    parts.append(truncated)
```

**Done when:** Features show content instead of "[Summary placeholder]".

---

# Phase 5: LLM Per-Feature Summaries

## Task 15: Add summarize_feature method

**Files:**
- Modify: `src/processor/content_processor.py`
- Test: `tests/test_processor.py`

**Step 1: Write failing test**

```python
def test_summarize_feature():
    """Test per-feature summarization."""
    processor = ContentProcessor(gemini_api_key="test")

    feature = Feature(
        category="Gradebook",
        name="Status Icons",
        anchor_id="status-icons",
        added_date=None,
        raw_content="<p>The Gradebook now shows status icons...</p>",
        table_data=None
    )

    summary = processor.summarize_feature(feature)
    assert len(summary) > 0
    assert len(summary) <= 300
```

**Step 2: Implement summarize_feature**

```python
def summarize_feature(self, feature: "Feature") -> str:
    """Generate a 2-3 sentence summary for a single feature.

    Args:
        feature: Feature object with raw_content.

    Returns:
        Concise summary string.
    """
    if not self.model or not feature.raw_content:
        # Fallback: extract and truncate text
        from bs4 import BeautifulSoup
        text = BeautifulSoup(feature.raw_content, 'html.parser').get_text()
        return text[:200].rsplit(' ', 1)[0] + "..." if len(text) > 200 else text

    prompt = f"""You are summarizing a Canvas LMS feature for educational technologists.

Feature: {feature.name}
Category: {feature.category}

Content:
{feature.raw_content}

Write a 2-3 sentence summary that covers:
1. What this feature does
2. Who benefits from it (students, instructors, admins)
3. The key improvement or capability it provides

Keep it concise and jargon-free."""

    return self._call_with_retry(
        lambda: self._generate_summary(prompt),
        fallback=feature.raw_content[:200]
    )
```

**Done when:** Features can be individually summarized.

---

## Task 16: Add summarize_deploy_change method

**Files:**
- Modify: `src/processor/content_processor.py`
- Test: `tests/test_processor.py`

Same pattern as Task 15, but with deploy-change-specific prompt:

```python
def summarize_deploy_change(self, change: "DeployChange") -> str:
    """Generate summary for a deploy change."""
    prompt = f"""You are summarizing a Canvas LMS change for educational technologists.

Change: {change.name}
Category: {change.category}
Section: {change.section}

Content:
{change.raw_content}

Write a 2-3 sentence summary that covers:
1. What behavior changed
2. Why it was changed (bug fix, improvement, accessibility, etc.)
3. Who needs to be aware of this change

Keep it concise and jargon-free."""
    # ... implementation ...
```

**Done when:** Deploy changes can be individually summarized.

---

## Task 17: Integrate per-feature summaries into main.py

**Files:**
- Modify: `src/main.py:194-252` and `src/main.py:255-313`
- Test: `tests/test_main.py`

**Step 1: Update process_release_notes**

After parsing page, summarize each feature before building entry:

```python
def process_release_notes(notes, db, scraper, processor):  # Add processor param
    for note in notes:
        page = scraper.parse_release_note_page(note.url)
        if page is None:
            continue

        # Generate summaries for each feature
        for feature in page.features:
            feature.summary = processor.summarize_feature(feature)

        # Now build_release_note_entry can use feature.summary
        description = build_release_note_entry(page, is_update, new_features)
        # ...
```

**Step 2: Update build_release_note_entry to use feature.summary**

```python
# In the feature loop:
if feature.summary:
    parts.append(feature.summary)
else:
    parts.append("[No summary available]")
```

**Done when:** RSS entries show per-feature LLM summaries.

---

# Phase 6: Integration Test

## Task 18: End-to-end integration test

**Files:**
- Add: `tests/test_v131_integration.py`

**Test cases:**

1. **Release note flow:** Parse page → classify features → summarize → build entry → RSS output
2. **Deploy note flow:** Parse page → classify changes → summarize → build entry → RSS output
3. **Discussion flow:** Classify posts → build title/description → RSS output
4. **Mixed feed:** Combine all content types, verify correct formatting for each

**Sample test:**

```python
def test_full_release_note_flow(mock_page, mock_db, mock_llm):
    """Test complete release notes flow produces correct RSS."""
    # Setup mocks
    mock_page.query_selector_all.return_value = [
        MockHeading(tag="h2", data_id="new-features", text="New Features"),
        MockHeading(tag="h3", data_id="gradebook", text="Gradebook"),
        MockHeading(tag="h4", data_id="status-icons", text="Status Icons Added"),
    ]
    mock_llm.return_value = "Status icons improve accessibility..."

    # Run flow
    scraper = InstructureScraper()
    scraper.page = mock_page
    processor = ContentProcessor()

    notes = [ReleaseNote(title="Canvas Release Notes (2026-02-01)", ...)]
    items = process_release_notes(notes, mock_db, scraper, processor)

    rss_builder = RSSBuilder()
    feed = rss_builder.create_feed(items)

    # Assertions
    assert "━━━ NEW FEATURES ━━━" in feed
    assert "▸ Gradebook - [Status Icons Added]" in feed
    assert "Status icons improve accessibility" in feed
    assert "<h3>Summary</h3>" not in feed  # No legacy HTML
```

**Done when:** Full integration test passes with expected RSS format.

---

## Summary of Changes

| File | Changes |
|------|---------|
| `src/processor/content_processor.py` | Add `structured_description` field, `summarize_feature()`, `summarize_deploy_change()` |
| `src/generator/rss_builder.py` | Update `_format_description()` to use structured content, fix `_format_title_with_badge()` |
| `src/scrapers/instructure_community.py` | Complete `parse_deploy_note_page()`, add `_get_next_sibling_content()`, `_parse_feature_table()`, upcoming_changes parsing |
| `src/main.py` | Use `structured_description`, add processor to process_* functions, integrate per-feature summaries |
| `tests/` | Add tests for all new functionality |

---

## Testing Strategy

- **Unit tests:** Each task includes specific test cases
- **Integration tests:** Task 18 covers end-to-end flow
- **Manual verification:** After implementation, run full aggregation and verify RSS output matches design spec

## Rollback Plan

All changes are additive. The `structured_description` field defaults to empty, so existing items will fall back to legacy HTML format. No database migrations required.

---

## Reference

- Original design: `docs/plans/2026-02-01-release-notes-enhanced-parsing.md`
- Deploy design: `docs/plans/2026-02-01-deploy-notes-parsing.md`
- Discussion design: `docs/plans/2026-02-01-discussion-tracking-design.md`
- v1.3.0 implementation: `docs/plans/2026-02-01-v1.3.0-unified-implementation.md`
